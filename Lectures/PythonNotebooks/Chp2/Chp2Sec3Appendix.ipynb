{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Basic Tutorial on Adjoint Based A Posteriori Error Analysis\n",
    "\n",
    "## (a.k.a. An Appendix to Section 2.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A forward (finite dimensional linear) problem\n",
    "Suppose $A\\in\\mathbb{R}^{n\\times n}$, $b\\in\\mathbb{R}^n$, and the goal is to determine $x\\in\\mathbb{R}^n$ such that \n",
    "\n",
    "$$\n",
    "\\large Ax = b.\n",
    "$$\n",
    "\n",
    "Here, $x$ is the vector of states, $A$ describes the relations between the states, and $b$ is the data.\n",
    "\n",
    "***In practice, we use numerical algorithms to generate a numerical solution $X\\approx x$.***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantifying error\n",
    "Having computed an approximate $X$, the ***uncomputable*** error is \n",
    "\n",
    "$$\n",
    "\\large e := x-X.\n",
    "$$\n",
    "\n",
    "However, the residual \n",
    "\n",
    "$$\n",
    "\\large R := b-AX\n",
    "$$\n",
    "\n",
    "is ***computable***, but given some norm on $\\mathbb{R}^n$, $R$ may be *small* even when $e$ is *large*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantities of interest\n",
    "We are often motivated to solve problems in order to compute a relatively small number of scalar ***Quantities of Interest (QoI)*** from the solution that correspond to important physical quantities. \n",
    "Many times, these QoI can be written as linear functionals of the solution. \n",
    "We then do not care so much about what the general error is in the numerical solution compared to how this error ***impacts*** the computed QoI that uses the numerical solution.\n",
    "For the sake of simplicity, assume we care about a single QoI that we denote by $Q$.\n",
    "\n",
    "#### [The Riesz Representation Theorem](https://en.wikipedia.org/wiki/Riesz_representation_theorem)\n",
    "> If $Q$ is linear functional of $x$, then there exists $\\psi\\in\\mathbb{R}^n$ such that\n",
    "<br><br>\n",
    "$$\n",
    "   \\large Q(x) = \\left< x, \\psi \\right>.\n",
    "$$\n",
    "<br>\n",
    "Here, $\\left<\\cdot,\\cdot\\right>$ is the usual inner product on $\\mathbb{R}^n$. \n",
    "\n",
    "With this Riesz Representation Theorem, we exploit the linearity of the inner product to write the error that we care about in the QoI as\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "    \\large e_Q &:=& \\large Q(x)-Q(X) \\\\ \\\\\n",
    "               &=&  \\large \\left<x,\\psi\\right> - \\left<X,\\psi\\right> \\\\ \\\\\n",
    "               &=&  \\large  \\left<x-X,\\psi\\right> \\\\ \\\\\n",
    "               &=&  \\large \\underbrace{\\left<e,\\psi\\right>}_{\\text{uncomputable}}.\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Uncomputable representations may be useful in theoretical settings, but in general, they have no practical utility. We seek to turn an uncomputable quantity into a computable quantity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving towards a computable estimate using the adjoint problem\n",
    "We define the adjoint problem as\n",
    "\n",
    "$$\n",
    "\\large A^\\top \\phi = \\psi.\n",
    "$$\n",
    "\n",
    "***Note that the data of the adjoint problem is determined by the QoI, and the structure of the adjoint operator is determined by the forward problem.***\n",
    "\n",
    "Suppose we solve the adjoint problem ***exactly*** to obtian $\\phi$ (we return to this assumption below). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A computable a posteriori error (estimate)\n",
    "We now exploit properties of the inner product and use the adjoint problem.\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "    \\large \\underbrace{\\left<e,\\psi\\right>}_{\\text{uncomputable}} &=&  \\large \\left<e,A^\\top\\phi\\right>  \\\\ \\\\\n",
    "               &=&  \\large  \\left<Ae,\\phi\\right> \\\\ \\\\\n",
    "               &=&  \\large \\underbrace{\\left<R,\\phi\\right>}_{\\text{computable}}.\n",
    "\\end{eqnarray*}\n",
    "\n",
    "We have derived a computable form of the a posteriori error that takes the form of the residual weighted by the adjoint solution.\n",
    "\n",
    "In general, we do not have the exact solution to the adjoint problem, $\\phi$, but rather a numerical estimate, $\\Phi\\approx\\phi$.\n",
    "Replacing $\\phi$ with $\\Phi$ results in a computable a posteroiri ***estimate*** given by\n",
    "\n",
    "$$\n",
    "    \\large e_Q \\approx \\left<R, \\Phi\\right>. \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a numerical environment in Python\n",
    "\n",
    "We use ``numpy`` so that we can work with arrays (matrices and vectors), and ``scipy`` for performing certain scientific computations in our example below. \n",
    "The library ``matplotlib`` is used for creating some visualizations.\n",
    "\n",
    "For more information on these packages, see http://scipy.org/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import scipy.sparse as sparse\n",
    "import scipy.sparse.linalg as splinalg\n",
    "import scipy.linalg as linalg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our forward problem\n",
    "\n",
    "Consider the two-point boundary value problem\n",
    "\n",
    "$$\n",
    "    \\large u'' = e^{\\alpha x}, \\ x\\in(0,1), \\ u(0)=u(1)=0.\n",
    "$$\n",
    "\n",
    "Here, $\\alpha$ is some parameter. \n",
    "We will play around with different values below. \n",
    "\n",
    "We use a three-point centered finite difference scheme on a uniform mesh of $(0,1)$ with grid spacing $h=0.05$ to discretize this problem into a matrix-vector problem of the form\n",
    "\n",
    "$$\n",
    "    \\large Au_h = b, \n",
    "$$\n",
    "\n",
    "where $u_h$ is a vector of nodal values that approximate the solution $u$ at the grid points of the mesh.\n",
    "\n",
    "***We are interested in $u_h$ not $u$ here. We simply use the differential equation to motivate the matrix-vector problem.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Setup computational grid\n",
    "alpha = 10.0  # Try 0.0 and 10.0\n",
    "h = .05\n",
    "xval = np.arange(h, 1.0, h)\n",
    "num_pts = len(xval)\n",
    "\n",
    "print(xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Discretize BVP \n",
    "\n",
    "# Step 1: Define data b\n",
    "# Uniform grid so can move h to right hand side\n",
    "b = h**2*np.exp(alpha*xval)\n",
    "\n",
    "# Step 2: Define matrix A\n",
    "# We use the spdiags command to map -1 2 1 to the tridiagonal matrix A\n",
    "temp = np.hstack((-np.ones((num_pts,1)), 2.0*np.ones((num_pts,1)), -np.ones((num_pts,1)))).transpose()\n",
    "A = sparse.spdiags(temp, [-1,0,1], num_pts, num_pts, format = \"csr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the forward problem\n",
    "\n",
    "We approximate the solution $U_h\\approx u_h$ by using seven iterations of the conjugate gradient method with no preconditioner (see https://en.wikipedia.org/wiki/Conjugate_gradient_method for more details on this method). \n",
    "\n",
    "We also obtain the \"exact\" $u_h$ by performing a direct solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the approximate solution with CG method\n",
    "(U_h,_) = splinalg.cg(A, b,tol=1.0e-20, maxiter=7)\n",
    "\n",
    "# Compute the \"exact\" solution\n",
    "u_h = splinalg.spsolve(A,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the QoI\n",
    "\n",
    "We assume we are interested in two QoI that are motivated by the continuous BVP:\n",
    "- $Q_1(u_h) = u_{h,9}$ (the 10*th* component of $u_h$ approximates $u(0.5)$)\n",
    "\n",
    "- $Q_2(u_h) = 0.2\\sum_{j=11}^{14} u_{h,j}$ (this weighted sum approximates the average value of $u$ over $[0.6,0.8]$)\n",
    "\n",
    "We see that these QoI correspond to inner products of $u_h$ with $\\psi_1$ and $\\psi_2$ where\n",
    "- $\\psi_{1,j} = 1$ if $j=9$ otherwise $\\psi_{1,j}=0$\n",
    "\n",
    "- $\\psi_{2,j}=0.2$ if $j=11,\\ldots,14$ otherwise $\\psi_{2,j}=0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the adjoint data vectors\n",
    "psi_1 = np.zeros((num_pts,1))\n",
    "psi_1[9] = 1\n",
    "\n",
    "psi_2 = np.zeros((num_pts,1))\n",
    "psi_2[11:15] = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and solve the adjoint problems\n",
    "\n",
    "We need to solve\n",
    "\n",
    "$$\n",
    "\\large A^\\top \\phi_1 = \\psi_1, \\ \\text{ and } \\ A^\\top\\phi_2 = \\psi_2.\n",
    "$$\n",
    "\n",
    "We solve the adjoint problems \"exactly\" using a direct solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phi_1 = splinalg.spsolve(A,psi_1)\n",
    "\n",
    "phi_2 = splinalg.spsolve(A,psi_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The adjoint solutions and a reliable a posteriori error estimate\n",
    "\n",
    "We now compute the errors in the two QoI using the computed values of `U_h` and `u_h` and compare to the computable a posteriori estimates. \n",
    "\n",
    "Recall that the a posteriori error estimates take the form of a residual weighted by the adjoint solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "R = b - A.dot(U_h)  # The residual\n",
    "\n",
    "err_est_1 = np.dot(R, phi_1)  # Error estimate for Q_1\n",
    "print(err_est_1)\n",
    "\n",
    "err_1 = u_h[9] - U_h[9]  # \"Exact error\"\n",
    "print(err_1)\n",
    "\n",
    "print('-'*50) \n",
    "\n",
    "err_est_2 = np.dot(R, phi_2)  # Error estimate for Q_2\n",
    "print(err_est_2)\n",
    "\n",
    "err_2 = np.sum(u_h[11:15]-U_h[11:15])*0.2\n",
    "print(err_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the results\n",
    "\n",
    "When working with manufactured solutions, we like to check that the ***effectivity ratio*** of the error estimate defined by the ratio of the error estimate to the actual error is close to one (assuming the actual error is not zero).\n",
    "\n",
    "We can also plot solutions and study the local error contributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "eff_1 = err_est_1/err_1\n",
    "print('Effectivity ratio of 1st error estimate: ', eff_1)\n",
    "\n",
    "print('-'*50)\n",
    "\n",
    "eff_2 = err_est_2/err_2\n",
    "print('Effectivity ratio of 2nd error estimate: ', eff_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "plt.figure(0)\n",
    "plt.plot(xval, U_h, 'b*', xval, u_h, 'r-')\n",
    "plt.legend(['$U_h$','$u_h$'])\n",
    "\n",
    "# Influence functions: Adjoint solutions\n",
    "plt.figure(1)\n",
    "plt.plot(xval, phi_1, xval, phi_2)\n",
    "plt.legend([r'$\\phi_1$',r'$\\phi_2$'])\n",
    "\n",
    "# \"Local Error Contributions\"\n",
    "plt.figure(2)\n",
    "plt.plot(xval, u_h-U_h, xval, R*phi_1, xval, R*phi_2)\n",
    "plt.legend(['$e(x)$', '$R\\phi_1$', '$R\\phi_2$'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A natural extension: Sensitivity analysis\n",
    "\n",
    "The data above depends upon the choice of $\\alpha$. \n",
    "In general, $A$ and $b$ may both depend upon some parameters that we collect into a vector we denote $\\lambda\\in\\mathbb{R}^m$.\n",
    "In other words, the problem is written as\n",
    "\n",
    "$$\n",
    "    \\large A(\\lambda)u_h = b(\\lambda), \n",
    "$$\n",
    "\n",
    "and clearly the solution $u_h$ depends upon the parameter (vector) $\\lambda$, so we write $u_h(\\lambda)$.\n",
    "Subsequently, $Q(u_h)$ also depends implicitly upon the parameter $\\lambda$, and we write $Q(\\lambda)$ to make this dependence explicit.\n",
    "Since parameters are often subject to uncertainty, we are commonly interested in the sensitivity of the QoI with respect to perturbations in these parameters. \n",
    "\n",
    "Let $\\lambda_i$ denote the $i$th component of the vector $\\lambda$ for $1\\leq i\\leq m$.\n",
    "Then, differentiating $A(\\lambda)u_h = b(\\lambda)$ with respect to $\\lambda_i$ and following a similar set of steps as used to derive the computable error estimate, we arrive at\n",
    "\n",
    "$$\n",
    " \\large\t\\partial_{\\lambda_i} Q(\\lambda) = \\left< \\partial_{\\lambda_i} {b}(\\lambda) - \\left[\\partial_{\\lambda_i}A(\\lambda)\\right] {u}(\\lambda), {\\phi}(\\lambda) \\right>.\n",
    "$$\n",
    "\n",
    "Here, $\\phi(\\lambda)$ depends upon $\\lambda$ since $A^\\top$ now also depends upon $\\lambda$. \n",
    "However, we only require the partial derivatives of the data and operator $A$ with respect to the parameters in order to determine the partial derivatives of $Q$. \n",
    "In other words, we solve ***two problems: the forward and adjoint problem*** and are able to determine the gradient of $Q$ even if $\\lambda$ has dimension in the millions. \n",
    "\n",
    "We leave the implementation for a future presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
